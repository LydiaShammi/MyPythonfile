"""
### Case study  - Uber Data Analysis

The data of a driverâ€™s uber trips are available for year 2016.
Your manager wants you to explore this data to give him some useful insights about the trip behaviour of a Uber driver.

#### Dataset - 
The dataset contains Start Date, End Date, Start Location, End Location, Miles Driven and Purpose of drive (Business, Personal, Meals, Errands, Meetings, Customer Support etc.)
"""

# ----------------------
# Concepts To cover 
# ----------------------
# 1. Data profiling
# 2. group by function
# 3. Apply function 
# 4. DateTime operations

# Import the libraries 


# Read the Data 


# View first n rows of data 
# n = 7


# View the last 5 rows of data


# Understand shape of data 


# There are 1156 rows and 7 columns in the dataset.

# Understand shape of data 

# size = total number of elements placed in 1D array.

# find null records

# Non-Null values


"""1. PURPOSE column has lots of missing values  
2. 1155 or 1156 records ??
"""



"""Show the records with missing values for column= PURPOSE """



"""How many records in purpose column are non-null  / have values ( in a particular column )"""

"""### Renaming columns"""

# Rename the columns to remove the * from the names
#or 
# Replace the * character from all the columns.


df.head()

"""### Filtering dataframes -1 """

# show the entries where PURPOSE is null


# inverting the selection ( not null ) ( works for booleans cases)


"""### Filtering dataframe - 2 """

# Conditions within dataframe 
#print df where STOP is Fort Pierce


# Inverting the selection 


"""Explore the details from the MILES column

"""

# Show the top 10 rides (*in terms of distance driven)


# Show the row that has the max miles 



# Get a summary of the numerical columns in the data and dataset using describe and info



"""The miles driven ranges from 0.5 miles to 12204 miles with an average of 21 miles

Max miles - looks suspect

#### Dropping rows  which have null values
"""

# Get the initial data with dropping the NA values
df_1 = df.copy()

# Removal of NULL values



# Get the shape of the dataframe after removing the null values



"""The filtered dataset with no nulls ( in PURPOSE column )  contains 653 rows of non-null values

### PANDAS PROFILING
Use some packages that will auto profile your data ( than having to manually type in all the commands )

You can find the documentation here ( https://pandas-profiling.github.io/pandas-profiling/docs/ )

Github page here - https://github.com/pandas-profiling/pandas-profiling
"""

# this just creates a webpage which is downloaded and can be opened in any web browser which can be used as a report to show to client
# try this code out
# if doing in jupyter pls run pip command given in next line once
# pip install pandas_profiling
import pandas_profiling as pp
profile = pp.ProfileReport(df_1)  # Of you just want to show here 

# output into an html file 
profile.to_file('output.html')
#if using colab this will be stored where you uploaded uber 2016 csv file, if using jupyter pls provide path for your desktop or any other place you want to save it
#before writing output.html e.g. 'yourpath\output.html'


"""### Lets explore the data parameter wise - 

1.Destination - (starting and stopping)

2.Time - (hour of the day, day of week, month of year)

3.Categories

4.Purpose 

5.Grouping two parameters to get more insights

## 1. Understanding  the start and stop points
"""

# Get the unique starting point, unique destination
# names of unique start points



# count of unique start points using len() or nunique


# count of unique start points using len()


# or use can use the nunique function


"""Stations which are appeared in both start and stop locations """


print(df[df['START'].isin(df['STOP'])][['START', 'STOP']])

# Identify popular start points - top 10



# Identify popular stop destinations - top 10



# Are there cases where the start and the stop location are the same  ? 
print(len(df[df['START'] == df['STOP']][['START', 'STOP']]))

# Favorite starting point wrt the total miles covered 
df.groupby(by='START').MILES.sum().sort_values(ascending=False)


# Starting Point with highest miles covered


"""#### Find out most farthest start and stop pair - top10 ( aggregation ) ( BY TOTAL miles COVERED EVER ! )"""

# Dropping Unknown Location Value  - Save into another dataframe ( you dont want to overwrite the original df)
df_2 = df[df['START'] != 'Unknown Location']
df_2 = df_2[df_2['STOP'] != 'Unknown Location']

"""The most popular start and stop pair - ( BY COUNT of travels! )"""

# The most popular start and stop pair - ( BY COUNT of travels!)
df_2.groupby(['START', 'STOP']).size().sort_values(ascending=False).reset_index(name = 'COUNT')

"""**The most popular start to destination pair is Morrisville-Cary**

## 2. Manipulating date & time objects
"""

df.head()

# Create columns by converting the start and end date into a datatime format
df['START_DATE'] = pd.to_datetime(df['START_DATE'])
df['END_DATE'] = pd.to_datetime(df['END_DATE'])
df.dtypes

df.head()

# Which month did he get most drives  ? 
df['Month'] = pd.DatetimeIndex(df['START_DATE']).month
df.head()

df['Month'].value_counts()

# Getting the average distance covered each month




# Which day did he get most drives  ? 
df['Day'] = pd.DatetimeIndex(df['START_DATE']).day
df['Day'].value_counts()

# Question1: How many miles was earned per category and purpose ?



# Question2: What is percentage of business miles vs personal?


