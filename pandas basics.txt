
import numpy as np
import pandas as pd

"""## GROUP BY

`DataFrame.groupby(by=None, axis=0, level=None, as_index=True, sort=True)`

Parameters :
* **by** : mapping, function, str, or iterable
axis : int, default 0
* **level** : If the axis is a MultiIndex (hierarchical), group by a particular level or levels
* **as_index** : For aggregated output, return object with group labels as the index. Only relevant for DataFrame input. as_index=False is effectively “SQL-style” 
grouped output
* **sort** : Sort group keys. Get better performance by turning this off. Note this does not influence the order of observations within each group. groupby preserves
 the order of rows within each group.
"""
  
# Define a dictionary containing employee data
data1 = {'Name':['Jai', 'Anuj', 'Jai', 'Princi',
                 'Gaurav', 'Anuj', 'Princi', 'Abhi'],
        'Age':[27, 24, 22, 32,
               33, 36, 27, 32],
        'Address':['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj',
                   'Jaunpur', 'Kanpur', 'Allahabad', 'Aligarh'],
        'Qualification':['Msc', 'MA', 'MCA', 'Phd',
                         'B.Tech', 'B.com', 'Msc', 'MA'],
             'Score': [23, 34, 35, 45, 47, 50, 52, 53]}
    
  
# Convert the dictionary into DataFrame 
df = pd.DataFrame(data1)
  
df

df = pd.DataFrame({'ID': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30],
                   'name': ['a','s','g','d','fd','df','sd','fsd','cx','v','dfd','xdv','fg','fg','r','th','ynj','hg','b','cx','gfh','xf','ghh','ynj',
                   'tj','ghh','fy','jhy','gfhykj','fg'],
                   'class_1': [3,4,5,5,4,3,5,5,4,3,4,3,3,3,4,5,4,3,5,3,5,4,4,5,4,3,3,5,3,4],
                   'house': ['yellow','red','blue','red','yellow','blue','red','red','blue','yellow','blue','red','red','blue','red','yellow','red',
                   'blue','red','yellow','red','blue','red','red','yellow','blue','red','yellow','yellow','yellow'],
                   'marks': [70,72,91,35,55,40,20,50,58,42,58,40,100,54,46,51,47,38,21,32,27,53,50,53,67,6,81,67,39,10]})

df

# Using groupby function
# with one key
 
grp_df_1 = df.groupby(by='house')
print(grp_df_1.groups)

# Using groupby function
# with one key
 
grp_df_1 = df.groupby(by='class_1').mean()
grp_df_1['marks']

grp_df_1 = df.groupby(by='house', axis=0)
print(grp_df_1.groups)

Marks = {'Name':['Jai', 'Anuj', 'Jai', 'Princi',
                 'Gaurav', 'Anuj', 'Princi', 'Abhi'],
             'Maths': [23, 34, 35, 45, 47, 50, 52, 53],
         'Physics': [45, 47, 50, 32, 23, 34, 35, 43],
         'Science': [34, 35, 45, 47, 50, 32, 23, 33],
         }
  
# Convert the dictionary into DataFrame 
dfm = pd.DataFrame(Marks)
  
dfm

#create DataFrame
df_marks = pd.DataFrame({'name': ['Amit', 'Amit', 'Amit', 'Amit', 'Bhushan', 'Bhushan', 'Bhushan', 'Bhushan'],
                         'term' : ['midterm 1', 'midterm 1','midterm 2','midterm 2','midterm 1', 'midterm 1','midterm 2','midterm 2'],
                   'subject': ['English', 'Science', 'English', 'Science', 'English', 'Science', 'English', 'Science'],
                   'marks': [46, 38, 59, 81, 43, 58, 68, 65]})

#define multiindex
df_marks.set_index(['name', 'term', 'subject'], inplace=True)

#view DataFrame
df_marks

# calculate sum of markes grouped by 2 levels of the multiindex
df_marks.groupby(level=['name', 'subject']).sum()
# either by or level, only one can be used

df.set_index(['class_1', 'house'], inplace=True)

df

df.groupby(level=['class_1', 'house']).mean()['marks']

df_marks.groupby(level=['name', 'subject']).max()

# applying groupby() function to
# group the data on Name value.
gk = df.groupby(by='Name')   ## Here groupby column is used ad index 
   
# Let's print the first entries
# in all the groups formed.
gk.first()

# Use as_index=False to treat groupby column as regular column
gk = df.groupby(by='Name', as_index=False)
   
# Let's print the first entries
# in all the groups formed.
gk.first()

# selecting a single group
 
grp = df.groupby('Name')
print(grp.get_group('Jai'))

# selecting object grouped
# on multiple columns
 
grp = df.groupby(['Name', 'Qualification'])
print(grp.get_group(('Jai', 'MCA')))

"""### Grouping Data with multiple keys"""

df

# Using multiple keys in
# groupby() function
grp_df_2 = df.groupby(['Name', 'Qualification'])
 
print(grp_df_2.groups)

# Groupby function with aggregation
 
df.groupby(['Name']).sum()
#age shouldnt get added though

df.groupby(['Name'])["Age"].sum() ## Output of this code will be a series

"""Like wise aggregation functions like sum(), max(), min(), count() etc"""

# applying a function by passing
# a list of functions
 
grp = df.groupby('Name')
print(grp) 
print(grp['Age'].agg([np.sum, np.mean, np.std]))

df

# using different aggregation
# function by passing dictionary
# to aggregate
grp = df.groupby(by='Name')
 
grp.agg({'Age' : ['mean', 'count'], 'Score' : ['std', 'mean', 'sum']})

df

dfx = pd.DataFrame({'ID': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30],
                   'name': ['a','s','g','d','fd','df','sd','fsd','cx','v','dfd','xdv','fg','fg','r','th','ynj','hg','b','cx','gfh','xf','ghh','ynj','tj',
                   'ghh','fy','jhy','gfhykj','fg'],
                   'class_1': [3,4,5,5,4,3,5,5,4,3,4,3,3,3,4,5,4,3,5,3,5,4,4,5,4,3,3,5,3,4],
                   'house': ['yellow','red','blue','red','yellow','blue','red','red','blue','yellow','blue','red','red','blue','red','yellow','red','blue',
                   'red','yellow','red','blue','red','red','yellow','blue','red','yellow','yellow','yellow'],
                   'marks': [70,72,91,35,55,40,20,50,58,42,58,40,100,54,46,51,47,38,21,32,27,53,50,53,67,6,81,67,39,10]})

dfx

grp1 = dfx.groupby(by='class_1')
grp1.agg({'marks':['sum', 'mean', 'count', 'min', 'max']})

dictionary1 = {'marks':['std', 'mean', 'median', 'min', 'max', 'count']}
dictionary1

grp2 = dfx.groupby(by=['class_1', 'house'])
grp2.agg({'marks':['std', 'mean', 'median', 'min', 'max', 'count']})

"""## Grouping by sorting keys"""

# We are getting the same results but we disabled the sorting 
# hence we are getting the results in the same as original order
grp = df.groupby(by='Name', sort=True)
 
grp.agg({'Age' : 'sum', 'Score' : 'std'})

df

# filtering data using
# filter data
grp = df.groupby('Name')
print(grp.agg('mean'))
grp.filter(lambda x: x['Score'].mean() >= 40)

dfx

grp1 = dfx.groupby(by='class_1')
grp1.agg({'marks':['sum', 'mean', 'count', 'min', 'max']})

grp1

grp1.filter(lambda x: x['marks'].mean() >= 50)

aa = list(dfx['marks'])
print(list(filter(lambda y: y >= 50 , aa)))

dfx[dfx.marks > 50]

"""## Sorting Values

`DataFrame.sort_values(by, axis=0, ascending=True, inplace=False, kind=’quicksort’, na_position=’last’)`

* **by**: Single/List of column names to sort Data Frame by. 
axis: 0 or ‘index’ for rows and 1 or ‘columns’ for Column. 
* **ascending**: Boolean value which sorts Data frame in ascending order if True. 
* **inplace**: Boolean value. Makes the changes in passed data frame itself if True. 
* **kind**: String which can have three inputs(‘quicksort’, ‘mergesort’ or ‘heapsort’) of algorithm used to sort data frame. 
* **na_position**: Takes two string input ‘last’ or ‘first’ to set position of Null values. Default is ‘last’.
"""

dfx

dfx.sort_values(by = 'class_1', ascending=False, ignore_index=True)

grp = df.groupby(by='Name')
grp1 = df.groupby(by='Name', as_index=False)

grp.agg({'Age' : 'sum', 'Score' : 'std'}).sort_values(by='Age', ascending=False)

agg_grp = grp1.agg({'Age' : 'sum', 'Score' : 'std'}).sort_values(by='Age', ascending=False)
agg_grp

grp.agg({'Age' : 'sum', 'Score' : 'std'}).sort_values(by='Age', ascending=False, ignore_index=True)

"""### Pivot tables in Pandas"""

#creating a dataframe
import numpy as np
df = pd.DataFrame({"A": ["foo", "foo", "foo", "foo", "foo",
                         "bar", "bar", "bar", "bar"],
                   "B": ["one", "one", "one", "two", "two",
                         "one", "one", "two", "two"],
                   "C": ["small", "large", "large", "small",
                         "small", "large", "small", "small",
                         "large"],
                   "D": [1, 2, 2, 3, 3, 4, 5, 6, 7],
                   "E": [2, 4, 5, 5, 6, 6, 8, 9, 9]})
df

#aggregating using sum
table = pd.pivot_table(df, values='D', index=['A', 'B'],
                    columns=['C'], aggfunc=np.sum)  #see numpy mathematical functions
table

dfx

table2 = pd.pivot_table(dfx, values='marks', index=['class_1','house'], aggfunc=np.mean)
table2

table3 = pd.pivot_table(dfx, values='marks', index='class_1', columns='house', aggfunc=np.mean)
table3

#using fill_value to fill the missing value
table1 = pd.pivot_table(df, values='D', index=['A', 'B'],
                    columns=['C'], aggfunc=np.sum, fill_value=0)
print(table1)

#using mean aggregate function
table2 = pd.pivot_table(df, values=['D', 'E'], index=['A'],columns=['C'],
                    aggfunc={'D': np.mean,
                             'E': np.mean})
table2

#using multiple aggregates at a time
table3 = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],
                    aggfunc={'D': np.mean,
                             'E': [min, max, np.mean]})
print(table3)

"""### Handling NULL values"""

import pandas as pd
d = {
      "a": [1, 2, 3, None],
      "b": [1, None, 3, None],
      "c": [1, 2, 3, None],
      "d": [1, 2, 3, None]
      }
df = pd.DataFrame(d)
print("The original DataFrame")
print(df)
print("\n-----------------------------")
print("Checking the given value is null or not")
print(df.isnull()) #check does given value is null

print("\n-----------------------------")
print("Checking the given value is not null or not")
print(df.notnull()) ##check does given value is not a null

print("\n-----------------------------")
print("Finding total missing value from each column")
print(df.isnull().sum()) # Additionally count the missing values.

## Replace all NaN elements with 0s.
df.fillna(0) #just displays and not saves

df

## Propagate non-null values forward ffill/bfill
df.fillna(method="bfill")

# Replace all NaN elements in column ‘a’, ‘b’, ‘c’, and ‘d’, with 0, 1, 2, and 3 respectively.
values = {"a": 0, "b": 1, "c": 2, "d": 3}
df.fillna(value=values)

print("-----------------------------")
df1 = df.dropna()
print("Rows with index 1 and 3 are dropped.")
print(df1)

print("\n-----------------------------")
print("Rows with index 3 are dropped, whose values are all NA")
df2 = df.dropna(how='all')
print(df2)

df.dropna(how='any')

print("-----------------------------")
print(df)
df3 = df.dropna(how='all',axis=1)
print(df3)